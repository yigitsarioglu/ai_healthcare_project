{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qL-Faql-Cj7V"
   },
   "source": [
    "# Assignment 2\n",
    "\n",
    "In this assignment you will implement ResNet18.\n",
    "Read the comments carefully and insert your code where you see: <br><br><b>##### START OF YOUR CODE #####</b><br><br><b>##### END OF YOUR CODE #####</b><br><br>or for the inline codes you will see<br><br><b>##### INSERT YOUR CODE HERE #####</b>\n",
    "\n",
    "### The architecture of ResNet-18 is shown in the table.\n",
    "First, we will define a convolutional block with skip connection. Then, create the model using these blocks.<br><br>\n",
    "<img src=\"https://www.researchgate.net/profile/Paolo-Napoletano/publication/322476121/figure/tbl1/AS:668726449946625@1536448218498/ResNet-18-Architecture.png\" width=\"500\" alt=\"ResNet18 Architecture\">\n",
    "\n",
    "<br><sup>Image ref: Napoletano, Paolo, et al. ‘Anomaly Detection in Nanofibrous Materials by CNN-Based Self-Similarity’. Sensors (Basel, Switzerland), vol. 18, 01 2018, https://doi.org10.3390/s18010209.</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X38vEzbBWFNt"
   },
   "source": [
    "#### I. ConvBlock\n",
    "<img src=\"https://www.researchgate.net/publication/334301817/figure/fig3/AS:778452965801986@1562609058538/Residual-block-of-ResNet18-with-a-1-1-convolutional-mapping-based-residual-unit-and.png\"><br>\n",
    "ResNet consists of convolutional (a) and identity (b) blocks. For ResNet-18 we will only use convolutional blocks. In this step you will write a class for convolutional block. The arguments will be:\n",
    "\n",
    "* ch_in: input channels\n",
    "* ch_out: output channels\n",
    "* s: strides\n",
    "* act: activation function\n",
    "\n",
    "The options for activation function are \"relu\", \"leaky_relu\" and \"gelu\".\n",
    "<br><br>\n",
    "<sup>Image ref: Owais, Muhammad, et al. ‘Artificial Intelligence-Based Classification of Multiple Gastrointestinal Diseases Using Endoscopy Videos for Clinical Diagnosis’. Journal of Clinical Medicine, vol. 8, 07 2019, p. 986, https://doi.org10.3390/jcm8070986.</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "w4zlwn3H8ZUR"
   },
   "outputs": [],
   "source": [
    "## 2022400354\n",
    "# Yiğit SARIOĞLU\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, ch_in, ch_out, s, act):\n",
    "      super(ConvBlock,self).__init__()\n",
    "\n",
    "      ##### START OF YOUR CODE #####\n",
    "\n",
    "       # Initialize layers\n",
    "\n",
    "       # this is the first convolutional layer of the block.\n",
    "       #it performs a 2D convolution operation with a specified number of input channel, output channel,kernel size ,stride and padding\n",
    "      self.conv1 = nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=s, padding=1)\n",
    "      self.bn1 = nn.BatchNorm2d(ch_out)\n",
    "\n",
    "      # this is the second convolutional layer of the block.\n",
    "      # it has the same number of input and output channels (ch_out) and uses a kernel size of 3x3, a stride of 1, and padding of 1.\n",
    "      self.conv2 = nn.Conv2d(ch_out, ch_out, kernel_size=3, stride=1, padding=1)\n",
    "      self.bn2 = nn.BatchNorm2d(ch_out)\n",
    "\n",
    "      if act == \"relu\":\n",
    "        self.activation = nn.ReLU()  #if act is relu it uses the rectified linear unit(ReLU) activation function.\n",
    "      elif act == \"leaky_relu\":\n",
    "        self.activation = nn.LeakyReLU()  #if act is leaky relu it uses the  Leaky ReLU activation function..\n",
    "      elif act == \"gelu\":\n",
    "        self.activation = nn.GELU() # if act is gelu it uses the GELU (Gaussian Error Linear Unit) activation function.\n",
    "      else:\n",
    "        raise ValueError(\"Invalid activation fuction...\") # if none of them, it gives an error\n",
    "\n",
    "\n",
    "\n",
    "      ##### END OF YOUR CODE #####\n",
    "\n",
    "    def forward(self, X):\n",
    "      ##### START OF YOUR CODE #####\n",
    "\n",
    "      # First conv layer\n",
    "      out = self.conv1(X)\n",
    "      out = self.bn1(out)\n",
    "      out = self.activation(out)\n",
    "\n",
    "      # Second convolutional layer\n",
    "      out = self.conv2(out)\n",
    "      out = self.bn2(out)\n",
    "\n",
    "      ##### END OF YOUR CODE #####\n",
    "      return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OS8xDz-ncs1F"
   },
   "source": [
    "#### II. ResNet18 class\n",
    "Use the ConvBlock class to create ResNet18.\n",
    "* Add batch normalization and activation function after all convolutional layers.\n",
    "* Examine the output sizes in the table and use paddings and strides where needed. (Note that the input size is 224 x 224 in this example)\n",
    "* Add a drop-out layer after average pooling.\n",
    "* Fully connected layer should be 512 x 1 as we have only 2 classes and we will use sigmoid function as the final activation layer.\n",
    "\n",
    "<img src=\"https://www.researchgate.net/profile/Paolo-Napoletano/publication/322476121/figure/tbl1/AS:668726449946625@1536448218498/ResNet-18-Architecture.png\" width=\"500\" alt=\"ResNet18 Architecture\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Npd7BHRsdFqt"
   },
   "outputs": [],
   "source": [
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, act, drop_rate):\n",
    "      super(ResNet18, self).__init__()\n",
    "      # Initialize layers\n",
    "      ##### START OF YOUR CODE #####\n",
    "\n",
    "      # Initialize layers\n",
    "      self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3) # this is the initial convolutional layer that takes a 224x224 input image with 3 input channels\n",
    "      self.bn1 = nn.BatchNorm2d(64)\n",
    "      self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "      # these represents the convolutional blocks in the ResNet architecture.\n",
    "      self.conv2_x = self._make_layer(64, 64, 2, act)  # self.conv2_x has two residual blocks with 64 input channels\n",
    "      self.conv3_x = self._make_layer(64, 128, 2, act, s=2)\n",
    "      self.conv4_x = self._make_layer(128, 256, 2, act, s=2)\n",
    "      self.conv5_x = self._make_layer(256, 512, 2, act, s=2) # self.conv5_x has two residual blocks with 512 input channels\n",
    "\n",
    "      self.avgpool = nn.AdaptiveAvgPool2d((1, 1)) # this layer performs adaptive average pooling\n",
    "      self.fc = nn.Linear(512, 1)  # this is the fully connected layer at the end of the network, it maps the 512-dimensional feature vector to a single output unit\n",
    "      self.dropout = nn.Dropout(drop_rate) # dropout layer with a specified dropout rate helps prevent overfitting\n",
    "\n",
    "      ##### END OF YOUR CODE #####\n",
    "\n",
    "    def forward(self, X):\n",
    "      ##### START OF YOUR CODE #####\n",
    "      X = self.conv1(X)\n",
    "      X = self.bn1(X)\n",
    "      X = F.relu(X)\n",
    "      X = self.pool(X)\n",
    "\n",
    "      X = self.conv2_x(X)\n",
    "      X = self.conv3_x(X)\n",
    "      X = self.conv4_x(X)\n",
    "      X = self.conv5_x(X)\n",
    "\n",
    "      X = self.avgpool(X)\n",
    "      X = X.view(X.size(0), -1)\n",
    "\n",
    "      X = self.fc(X)\n",
    "      X = self.dropout(X)\n",
    "      return X\n",
    "\n",
    "    def _make_layer(self, in_channels, out_channels, num_blocks, act, s=1):\n",
    "\n",
    "        layers = []\n",
    "        layers.append(ConvBlock(in_channels, out_channels, s, act))\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(ConvBlock(out_channels, out_channels, 1, act))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "      ##### END OF YOUR CODE #####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dvviIPvsSj6y",
    "outputId": "e547c8f6-527d-45af-b601-7fe9886e7554"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet18(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (conv2_x): Sequential(\n",
      "    (0): ConvBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (1): ConvBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (conv3_x): Sequential(\n",
      "    (0): ConvBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (1): ConvBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (conv4_x): Sequential(\n",
      "    (0): ConvBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (1): ConvBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (conv5_x): Sequential(\n",
      "    (0): ConvBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (1): ConvBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Print the model\n",
    "model = ResNet18(\"relu\", .5)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RNs2QjRLq3x4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
