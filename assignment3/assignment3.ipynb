{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HUzFO3Za-AU4"
   },
   "source": [
    "### 1. Download the Data from Kaggle and Unzip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_g1YiJKHK5M8"
   },
   "outputs": [],
   "source": [
    "!pip install -q kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YTnECrlJK7UP"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RPS6a8XtLY1t"
   },
   "outputs": [],
   "source": [
    "!mkdir ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "!kaggle datasets download -d 'maedemaftouni/large-covid19-ct-slice-dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P5ghbm_EsCVK"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/gdrive\") # Connect to google drive as we will save model weights here\n",
    "shutil.unpack_archive(\"/content/large-covid19-ct-slice-dataset.zip\", \"/tmp/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dD8e2UClO0Wf"
   },
   "source": [
    "### 1. OR Unzip the data if you have uploaded it to drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UW5CWRBoPgIp",
    "outputId": "5b05b4ba-1be1-4583-b576-f688c5409263"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/gdrive\")\n",
    "# Change the code below if the path to the dataset is different for you.\n",
    "shutil.unpack_archive(\"/content/gdrive/MyDrive/archive.zip\", \"/tmp/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QMKxclhvd9fz"
   },
   "source": [
    "### 2. Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a6sKDOT9lO4P",
    "outputId": "d484a16d-4e0d-4f07-e4ed-45106501db85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal\n",
      "Number of patient:  604\n",
      "Number of image:  6893\n",
      "\n",
      "Covid\n",
      "Number of patient:  464\n",
      "Number of image:  7593\n",
      "\n",
      "CAP\n",
      "Number of patient:  54\n",
      "Number of image:  2618\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "meta_normal = pd.read_csv(\"/tmp/meta_data_normal.csv\")\n",
    "meta_covid = pd.read_csv(\"/tmp/meta_data_covid.csv\", encoding='windows-1252')\n",
    "meta_cap = pd.read_csv(\"/tmp/meta_data_cap.csv\")\n",
    "\n",
    "# Define the variables below using meta dataframes\n",
    "\n",
    "normal_pt_nb = len(pd.unique(meta_normal[\"Patient ID\"])) ##### INSERT YOUR CODE HERE ##### # Number of patients in normal group\n",
    "covid_pt_nb = len(pd.unique(meta_covid[\"Patient ID\"])) ##### INSERT YOUR CODE HERE ##### # Number of patients in covid group\n",
    "cap_pt_nb = len(pd.unique(meta_cap[\"Patient ID\"])) ##### INSERT YOUR CODE HERE ##### # Number of patients in CAP group\n",
    "\n",
    "normal_img_nb = len(meta_normal) ##### INSERT YOUR CODE HERE ##### # Number of images in normal group\n",
    "covid_img_nb = len(meta_covid) ##### INSERT YOUR CODE HERE ##### # Number of images in covid group\n",
    "cap_img_nb = len(meta_cap) ##### INSERT YOUR CODE HERE ##### # Number of images in CAP group\n",
    "\n",
    "print(\"Normal\")\n",
    "print(\"Number of patient: \", normal_pt_nb)\n",
    "print(\"Number of image: \", normal_img_nb)\n",
    "\n",
    "print(\"\\nCovid\")\n",
    "print(\"Number of patient: \", covid_pt_nb)\n",
    "print(\"Number of image: \", covid_img_nb)\n",
    "\n",
    "print(\"\\nCAP\")\n",
    "print(\"Number of patient: \", cap_pt_nb)\n",
    "print(\"Number of image: \", cap_img_nb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CBbpEW_6qVHJ",
    "outputId": "de99ee81-4434-4470-b671-1030e15e9744"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice-based val size: \n",
      "Normal:  0.21\n",
      "Covid:  0.18\n",
      "\n",
      "Slice-based test size: \n",
      "Normal:  0.51\n",
      "Covid:  0.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "# Set seed to get the same result (I specifically chose this seed after a couple of tries so that we'll have approximately same split ratios on slice level as well)\n",
    "np.random.seed(58)\n",
    "val_split_size = .2\n",
    "test_split_size = .5\n",
    "\n",
    "normal_val_file_list, normal_test_file_list = [], []\n",
    "covid_val_file_list, covid_test_file_list = [], []\n",
    "##### START OF YOUR CODE #####\n",
    "normal_pt_list = np.array(pd.unique(meta_normal[\"Patient ID\"]))\n",
    "np.random.shuffle(normal_pt_list)\n",
    "normal_val_pts = normal_pt_list[:int(normal_pt_nb * val_split_size)]\n",
    "normal_test_pts = normal_pt_list[int(normal_pt_nb * val_split_size): int(normal_pt_nb * (val_split_size+test_split_size))]\n",
    "\n",
    "normal_val_file_list = []\n",
    "for pt in normal_val_pts:\n",
    "  for i in meta_normal[\"File name\"][meta_normal[\"Patient ID\"] == pt].values:\n",
    "    normal_val_file_list.append(i)\n",
    "\n",
    "normal_test_file_list = []\n",
    "for pt in normal_test_pts:\n",
    "  for i in meta_normal[\"File name\"][meta_normal[\"Patient ID\"] == pt].values:\n",
    "    normal_test_file_list.append(i)\n",
    "\n",
    "covid_pt_list = np.array(pd.unique(meta_covid[\"Patient ID\"]))\n",
    "np.random.shuffle(covid_pt_list)\n",
    "covid_val_pts = covid_pt_list[:int(covid_pt_nb * val_split_size)]\n",
    "covid_test_pts = covid_pt_list[int(covid_pt_nb * val_split_size): int(covid_pt_nb * (val_split_size+test_split_size))]\n",
    "\n",
    "covid_val_file_list = []\n",
    "for pt in covid_val_pts:\n",
    "  for i in meta_covid[\"File name\"][meta_covid[\"Patient ID\"] == pt].values:\n",
    "    covid_val_file_list.append(i)\n",
    "\n",
    "covid_test_file_list = []\n",
    "for pt in covid_test_pts:\n",
    "  for i in meta_covid[\"File name\"][meta_covid[\"Patient ID\"] == pt].values:\n",
    "    covid_test_file_list.append(i)\n",
    "\n",
    "##### END OF YOUR CODE #####\n",
    "\n",
    "print(\"Slice-based val size: \")\n",
    "print(\"Normal: \", round(len(normal_val_file_list)/normal_img_nb, 2))\n",
    "print(\"Covid: \", round(len(covid_val_file_list)/covid_img_nb, 2))\n",
    "\n",
    "print(\"\\nSlice-based test size: \")\n",
    "print(\"Normal: \", round(len(normal_test_file_list)/normal_img_nb, 2))\n",
    "print(\"Covid: \", round(len(covid_test_file_list)/covid_img_nb, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EdYip6S1qZh_",
    "outputId": "13bcf095-d66b-4f1c-ead6-3647a17dcd48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Percentage of train set: 0.30\n",
      "Percentage of Covid + slices in train set is: 0.55\n",
      "\n",
      "Percentage of val set: 0.19\n",
      "Percentage of Covid + slices in val set is: 0.49\n",
      "\n",
      "Percentage of test set: 0.51\n",
      "Percentage of Covid + slices in test set is: 0.52\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "##### START OF YOUR CODE #####\n",
    "# Create train and test directories and move the files accordingly\n",
    "[os.makedirs(\"/tmp/curated_data/data/\"+x+y, exist_ok=True) for x in [\"train/\", \"val/\", \"test/\"] for y in [\"normal/\", \"covid/\"]]\n",
    "\n",
    "# Normal group\n",
    "for pt in os.listdir(\"/tmp/curated_data/curated_data/1NonCOVID/\"):\n",
    "  # validation\n",
    "  if pt in normal_val_file_list:\n",
    "    shutil.move(\"/tmp/curated_data/curated_data/1NonCOVID/\"+pt, \"/tmp/curated_data/data/val/normal/\")\n",
    "  # test\n",
    "  elif pt in normal_test_file_list:\n",
    "    shutil.move(\"/tmp/curated_data/curated_data/1NonCOVID/\"+pt, \"/tmp/curated_data/data/test/normal/\")\n",
    "  # train\n",
    "  else:\n",
    "    shutil.move(\"/tmp/curated_data/curated_data/1NonCOVID/\"+pt, \"/tmp/curated_data/data/train/normal/\")\n",
    "\n",
    "# Covid group\n",
    "for pt in os.listdir(\"/tmp/curated_data/curated_data/2COVID/\"):\n",
    "  # validation\n",
    "  if pt in covid_val_file_list:\n",
    "    shutil.move(\"/tmp/curated_data/curated_data/2COVID/\"+pt, \"/tmp/curated_data/data/val/covid/\")\n",
    "  # test\n",
    "  elif pt in covid_test_file_list:\n",
    "    shutil.move(\"/tmp/curated_data/curated_data/2COVID/\"+pt, \"/tmp/curated_data/data/test/covid/\")\n",
    "  # train\n",
    "  else:\n",
    "    shutil.move(\"/tmp/curated_data/curated_data/2COVID/\"+pt, \"/tmp/curated_data/data/train/covid/\")\n",
    "\n",
    "##### END OF YOUR CODE #####\n",
    "\n",
    "data_counts = {x+y: len(os.listdir(\"/tmp/curated_data/data/\"+x+y)) for x in [\"train/\", \"val/\", \"test/\"] for y in [\"normal/\", \"covid/\"]}\n",
    "for i in [\"train\", \"val\", \"test\"]:\n",
    "  print(\"\\nPercentage of {} set: {:.2f}\" .format(i, (data_counts[i+\"/normal/\"]+data_counts[i+\"/covid/\"])/sum(data_counts.values())))\n",
    "  print(\"Percentage of Covid + slices in {} set is: {:.2f}\" .format(i, data_counts[i+\"/covid/\"]/(data_counts[i+\"/normal/\"]+data_counts[i+\"/covid/\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j1LyhJcvl70h"
   },
   "source": [
    "### 3. Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jtsYoaUfAN3i",
    "outputId": "a4134eab-2418-4f4c-fa25-105cfcc76490"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.8/172.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q torchio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "HT7wX3DxgxP-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torchio as tio\n",
    "import torchvision.transforms as T\n",
    "\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, image_size, data_folder, partition):\n",
    "    ##### START OF YOUR CODE #####\n",
    "    self.image_size = image_size\n",
    "    self.partition = partition\n",
    "    self.data_folder = data_folder\n",
    "    self.paths = self.img_paths()\n",
    "\n",
    "    ##### END OF YOUR CODE #####\n",
    "  def __len__(self):\n",
    "\n",
    "    ##### START OF YOUR CODE #####\n",
    "    return len(self.paths)\n",
    "    ##### END OF YOUR CODE #####\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "\n",
    "    ##### START OF YOUR CODE #####\n",
    "    img = self.read_and_resize_img(self.paths[idx])\n",
    "    label = int(self.paths[idx].rsplit(\"/\", 2)[1] == \"covid\")\n",
    "    label = np.array(label)[np.newaxis]\n",
    "\n",
    "    if self.partition == \"train\":\n",
    "        img = self.augmentation(img)\n",
    "    return (img, label)\n",
    "\n",
    "    ##### END OF YOUR CODE #####\n",
    "\n",
    "  def img_paths(self):\n",
    "    ##### START OF YOUR CODE #####\n",
    "    normal_paths = [os.path.join(self.data_folder, self.partition, \"normal\", i) for i in os.listdir(os.path.join(self.data_folder, self.partition, \"normal\"))]\n",
    "    covid_paths = [os.path.join(self.data_folder, self.partition, \"covid\", i) for i in os.listdir(os.path.join(self.data_folder, self.partition, \"covid\"))]\n",
    "    paths = normal_paths + covid_paths\n",
    "    np.random.shuffle(paths)\n",
    "    return paths\n",
    "\n",
    "    ##### END OF YOUR CODE #####\n",
    "\n",
    "  def read_and_resize_img(self, path):\n",
    "    ##### START OF YOUR CODE #####\n",
    "    img = Image.open(path).convert('L')\n",
    "    img = np.array(img)[np.newaxis]/255.\n",
    "\n",
    "    if (self.image_size, self.image_size) != img.shape[1:]:\n",
    "      resizing = T.Resize((self.image_size, self.image_size), antialias=False)\n",
    "      resized_img = resizing(torch.Tensor(img))\n",
    "      return resized_img\n",
    "\n",
    "    return torch.Tensor(img)\n",
    "\n",
    "    ##### END OF YOUR CODE #####\n",
    "\n",
    "  def augmentation(self, data):\n",
    "    ##### START OF YOUR CODE #####\n",
    "\n",
    "    transform = tio.transforms.OneOf({\n",
    "        tio.transforms.OneOf({\n",
    "            tio.transforms.RandomNoise(): .25,\n",
    "            tio.transforms.RandomBiasField(): .25,\n",
    "            tio.transforms.RandomGhosting(): .25,\n",
    "            tio.transforms.RandomSpike(): .25,\n",
    "            tio.transforms.RandomAffine(degrees=10, scales=0., translation=0.): .25\n",
    "        }): .8\n",
    "    })\n",
    "    aug_data = torch.squeeze(transform(torch.unsqueeze(data, -1)), -1)\n",
    "    return aug_data\n",
    "\n",
    "\n",
    "    ##### END OF YOUR CODE #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wEN_w6q3tbZM"
   },
   "source": [
    "### 4. ResNet-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "w4zlwn3H8ZUR"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, ch_in, ch_out, s, act):\n",
    "      super(ConvBlock,self).__init__()\n",
    "      # Initialize layers\n",
    "\n",
    "      ##### START OF YOUR CODE #####\n",
    "      super(ConvBlock,self).__init__()\n",
    "      # Initialize layers\n",
    "      if act == \"relu\":\n",
    "          self.act_layer = nn.ReLU()\n",
    "      elif act == \"leaky_relu\":\n",
    "          self.act_layer = nn.LeakyReLU()\n",
    "      elif act == \"gelu\":\n",
    "          self.act_layer = nn.GELU()\n",
    "\n",
    "      self.conv1 = nn.Conv2d(ch_in, ch_in, kernel_size=3, stride=s, padding=1)\n",
    "      self.bn1 = nn.BatchNorm2d(ch_in)\n",
    "      self.conv2 = nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1, padding=1)\n",
    "      self.bn2 = nn.BatchNorm2d(ch_out)\n",
    "\n",
    "      self.conv_sc = nn.Conv2d(ch_in, ch_out, kernel_size=1, stride=s)\n",
    "      self.bn_sc = nn.BatchNorm2d(ch_out)\n",
    "\n",
    "\n",
    "      ##### END OF YOUR CODE #####\n",
    "\n",
    "    def forward(self, X):\n",
    "      ##### START OF YOUR CODE #####\n",
    "      X_shortcut = X\n",
    "      X = self.bn1(self.conv1(X))\n",
    "      X = self.act_layer(X)\n",
    "      X = self.bn2(self.conv2(X))\n",
    "\n",
    "      X_shortcut = self.bn_sc(self.conv_sc(X_shortcut))\n",
    "      X = self.act_layer(X + X_shortcut)\n",
    "\n",
    "\n",
    "      ##### END OF YOUR CODE #####\n",
    "      return X\n",
    "\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, act, drop_rate, image_size):\n",
    "      super(ResNet18, self).__init__()\n",
    "      # Initialize layers\n",
    "      ##### START OF YOUR CODE #####\n",
    "\n",
    "      if act == \"relu\":\n",
    "          self.act_layer = nn.ReLU()\n",
    "      elif act == \"leaky_relu\":\n",
    "          self.act_layer = nn.LeakyReLU()\n",
    "      elif act == \"gelu\":\n",
    "          self.act_layer = nn.GELU()\n",
    "\n",
    "      self.image_size = image_size\n",
    "\n",
    "      self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3) # 64 x N/2 x N/2\n",
    "      self.bn1 = nn.BatchNorm2d(64)\n",
    "\n",
    "      self.mp = nn.MaxPool2d((3, 3), stride=2, padding=1) # 64 x N/4 x N/4\n",
    "      self.conv2a = ConvBlock(64, 64, 1, act)\n",
    "      self.conv2b = ConvBlock(64, 64, 1, act) # 64 x N/4 x N/4\n",
    "\n",
    "      self.conv3a = ConvBlock(64, 128, 2, act)\n",
    "      self.conv3b = ConvBlock(128, 128, 1, act) # 128 x N/8 x N/8\n",
    "\n",
    "      self.conv4a = ConvBlock(128, 256, 2, act)\n",
    "      self.conv4b = ConvBlock(256, 256, 1, act) # 256 x N/16 x N/16\n",
    "\n",
    "      self.conv5a = ConvBlock(256, 512, 2, act)\n",
    "      self.conv5b = ConvBlock(512, 512, 1, act) # 512 x N/32 x N/32\n",
    "\n",
    "      kernel_size = self.image_size /(2**5)\n",
    "      self.avgpool = nn.AvgPool2d((int(kernel_size), int(kernel_size)))\n",
    "      self.flat = nn.Flatten()\n",
    "      self.dropout = nn.Dropout(drop_rate)\n",
    "      self.fc = nn.Linear(512, 1)\n",
    "\n",
    "      ##### END OF YOUR CODE #####\n",
    "\n",
    "    def forward(self, X):\n",
    "      ##### START OF YOUR CODE #####\n",
    "\n",
    "      batch_size = X.size(0)\n",
    "      image_size = X.size(2)\n",
    "\n",
    "      X = self.conv1(X)\n",
    "      X = self.bn1(X)\n",
    "      X = self.act_layer(X)\n",
    "\n",
    "      X = self.mp(X)\n",
    "      X = self.conv2a(X)\n",
    "      X = self.conv2b(X)\n",
    "\n",
    "      X = self.conv3a(X)\n",
    "      X = self.conv3b(X)\n",
    "\n",
    "      X = self.conv4a(X)\n",
    "      X = self.conv4b(X)\n",
    "\n",
    "      X = self.conv5a(X)\n",
    "      X = self.conv5b(X)\n",
    "\n",
    "      X = self.avgpool(X)\n",
    "      X = self.flat(X)\n",
    "      X = self.fc(self.dropout(X))\n",
    "      X = torch.sigmoid(X)\n",
    "\n",
    "      ##### END OF YOUR CODE #####\n",
    "      return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yK6dM2ZheLg2",
    "outputId": "2fb21161-8aa3-44df-f16e-8d6737ca44e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet18(\n",
      "  (act_layer): ReLU()\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (mp): MaxPool2d(kernel_size=(3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (conv2a): ConvBlock(\n",
      "    (act_layer): ReLU()\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv_sc): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (bn_sc): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv2b): ConvBlock(\n",
      "    (act_layer): ReLU()\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv_sc): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (bn_sc): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv3a): ConvBlock(\n",
      "    (act_layer): ReLU()\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv_sc): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
      "    (bn_sc): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv3b): ConvBlock(\n",
      "    (act_layer): ReLU()\n",
      "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv_sc): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (bn_sc): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv4a): ConvBlock(\n",
      "    (act_layer): ReLU()\n",
      "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv_sc): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
      "    (bn_sc): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv4b): ConvBlock(\n",
      "    (act_layer): ReLU()\n",
      "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv_sc): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (bn_sc): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv5a): ConvBlock(\n",
      "    (act_layer): ReLU()\n",
      "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv_sc): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
      "    (bn_sc): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv5b): ConvBlock(\n",
      "    (act_layer): ReLU()\n",
      "    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv_sc): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (bn_sc): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (avgpool): AvgPool2d(kernel_size=(7, 7), stride=(7, 7), padding=0)\n",
      "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Print the model\n",
    "model = ResNet18(\"relu\", .5, 224)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BmljrzaQfZ2s"
   },
   "source": [
    "# Assignment 3\n",
    "<p>In this assignment you will\n",
    "\n",
    "* write helper functions\n",
    "* train the model\n",
    "* hyperparameter search using W&B\n",
    "\n",
    "Read the comments carefully and insert your code where you see: <br><br><b>##### START OF YOUR CODE #####</b><br><br><b>##### END OF YOUR CODE #####</b><br><br>or for the inline codes you will see<br><br><b>##### INSERT YOUR CODE HERE #####</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iUnVIVdtY3x0"
   },
   "source": [
    "#### I. AverageMeter\n",
    "First we will write a helper function. AverageMeter is to calculate the mean of the running loss and accuracy.\n",
    "\n",
    "*   It will have 2 functions which are reset and update.\n",
    "*   reset will be called on initialization and set the attributes to 0.\n",
    "*   update takes 2 arguments for the value and the size. It will add the value to the sum and the size to the count. Attribute \"avg\" (use this name) will also be updated as sum/count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "A38OLNLbYwfa"
   },
   "outputs": [],
   "source": [
    "## YİĞİT SARIOĞLU\n",
    "# STUDENT NO: 2022400354\n",
    "\n",
    "class AverageMeter:\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "     ##### START OF YOUR CODE #####\n",
    "\n",
    "    #constructor method: Initializes the object and calls the reset method.\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    # resets the sum and count attributes to 0.\n",
    "    def reset(self):\n",
    "        self.sum = 0.0\n",
    "        self.count = 0\n",
    "\n",
    "    # updates the sum and count based on the given value and size\n",
    "    def update(self, value, size):\n",
    "        self.sum += value * size\n",
    "        self.count += size\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "      ##### END OF YOUR CODE #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eCFUuYR7agXr",
    "outputId": "e1301ae1-b447-4179-e42b-69b08c9ca6b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.0 10\n"
     ]
    }
   ],
   "source": [
    "avg_meter = AverageMeter()\n",
    "avg_meter.update(100, 5)\n",
    "avg_meter.update(50, 5)\n",
    "print(avg_meter.avg, avg_meter.count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pk3vHad6dhhf"
   },
   "source": [
    "#### II. Train Loop\n",
    "Now we will write the training and validation loops. Detailed instructions are given within the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "NqmEhWg6befh"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "\n",
    "def accuracy(outputs, labels):\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    total = labels.size(0)\n",
    "    acc = correct / total\n",
    "    return acc\n",
    "\n",
    "\n",
    "def training(train_loader, model, criterion, optimizer):\n",
    "  # Let's start by initializing our AverageMeters.\n",
    "  avg_meters = {'loss': AverageMeter(),\n",
    "                'acc': AverageMeter()}\n",
    "\n",
    "  # We will go through the train_loader.\n",
    "  # Zero the gradients.\n",
    "  # Make prediction.\n",
    "  # Calculate the loss and the accuracy using prediction and labels.\n",
    "  # Update the average meters.\n",
    "  # Compute gradients and adjust learning weights.\n",
    "\n",
    "  ##### START OF YOUR CODE #####\n",
    "\n",
    "  # We will go through the train_loader.\n",
    "  for inputs, labels in train_loader:\n",
    "      # move inputs and labels to the device (GPU).\n",
    "      inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "\n",
    "      # zero the gradients.\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # makes predictions\n",
    "      outputs = model(inputs)\n",
    "\n",
    "\n",
    "\n",
    "      # convert labels to float to match the criterion.\n",
    "      labels = labels.float()\n",
    "\n",
    "      loss = criterion(outputs, labels)\n",
    "\n",
    "      acc = accuracy(outputs, labels)\n",
    "\n",
    "\n",
    "      # Update the average meters.\n",
    "      avg_meters['loss'].update(loss.item(), inputs.size(0))\n",
    "      avg_meters['acc'].update(acc, inputs.size(0))\n",
    "\n",
    "      # compute gradients and adjust learning weights.\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "\n",
    "  ##### END OF YOUR CODE #####\n",
    "\n",
    "  return dict([('loss', avg_meters['loss'].avg),\n",
    "                ('acc', avg_meters['acc'].avg)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def validation(val_loader, model, criterion):\n",
    "  avg_meters = {'loss': AverageMeter(),\n",
    "                'acc': AverageMeter()}\n",
    "\n",
    "  # Validation is almost the same but don't forget to turn the eval mode of the model and with torch no_grad.\n",
    "  # You don't need to compute gradients or adjust learning weights for evaluation.\n",
    "\n",
    "  ##### START OF YOUR CODE #####\n",
    "  model.eval()  # set(model) to evaluation mode\n",
    "  with torch.no_grad():  #\n",
    "    for inputs, labels in val_loader:\n",
    "      # move inputs and labels to the device (GPU).\n",
    "      inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "      # prediction\n",
    "      outputs = model(inputs)\n",
    "\n",
    "       # convert labels to float\n",
    "      labels = labels.float()\n",
    "\n",
    "\n",
    "\n",
    "      # calculate the loss and the accuracy using prediction and labels.\n",
    "      loss = criterion(outputs, labels)\n",
    "      acc = accuracy(outputs, labels)\n",
    "\n",
    "\n",
    "      # update the average meters.\n",
    "      avg_meters['loss'].update(loss.item(), inputs.size(0))\n",
    "\n",
    "      avg_meters['acc'].update(acc, inputs.size(0))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  ##### END OF YOUR CODE #####\n",
    "\n",
    "  return dict([('loss', avg_meters['loss'].avg),\n",
    "              ('acc', avg_meters['acc'].avg)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P1ZChNtVfyRw"
   },
   "source": [
    "We will use Weights & Biases for hyperparameter search. This will only be an introduction and we highly recommend you to read the <a href=\"https://docs.wandb.ai/?_gl=1*1xon9b*_ga*NDg5OTYzNTM3LjE2NzUwNjYzNjk.*_ga_JH1SJHJQXJ*MTY3Njc0MDEyNi4xMi4xLjE2NzY3NDAxMjguNTguMC4w\">documentation</a> for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H4uhE_s3cRvo",
    "outputId": "037466f2-b961-4962-c8db-2dba68dcdb43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wandb\n",
      "  Downloading wandb-0.16.0-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
      "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
      "  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
      "  Downloading sentry_sdk-1.36.0-py2.py3-none-any.whl (249 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.2/249.2 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
      "Collecting setproctitle (from wandb)\n",
      "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
      "Successfully installed GitPython-3.1.40 docker-pycreds-0.4.0 gitdb-4.0.11 sentry-sdk-1.36.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "rWk9ArIm_hoQ"
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import os\n",
    "\n",
    "import wandb\n",
    "\n",
    "\n",
    "def main():\n",
    "  print(\"here i am 0\")\n",
    "  # Set the initial configuration\n",
    "  initial_config = {\n",
    "      \"data_dir\": \"/tmp/curated_data/data/\",\n",
    "      \"image_size\": 128,\n",
    "      \"train_batch_size\": 64,\n",
    "      \"val_batch_size\": 32,\n",
    "      \"test_batch_size\": 1,\n",
    "      \"activation\": \"relu\",\n",
    "      \"drop_rate\": .2,\n",
    "      \"optimizer\": \"Adam\",\n",
    "      \"learning_rate\": 1e-3,\n",
    "      \"l2_reg\": 1e-4, # Weight decay\n",
    "      \"nb_epoch\": 50,\n",
    "      \"early_stopping\": 15, # trigger value for early stopping\n",
    "\n",
    "  }\n",
    "\n",
    "  # Using this configuration dictionary:\n",
    "  # initialize wandb\n",
    "  # Create a run directory in your drive (\"/content/drive/MyDrive/CMPE_runs/\" + the current run name that you'll get from wandb)\n",
    "  # Create the model\n",
    "  # Create dataloader dictionary with \"train\", \"val\", \"test\" keys\n",
    "  # Define binary cross entropy loss\n",
    "  # Define optimizer with weight decay\n",
    "  # Set lr scheduler to ReduceLROnPlateau:\n",
    "    # It will decrease the lr by .1 if the val_loss did not decrease > .01. The minimum lr value can be 1e-9.\n",
    "  # Print train and val results and log them to wandb at the end of each epoch\n",
    "  # Save best model weights to your run directory when the val accuracy is at least .01 better than the best val accuracy.\n",
    "  # Set early stopping with the trigger in config[\"early_stopping\"], monitoring val accuracy. config[\"early_stopping\"] = -1 means no early stopping.\n",
    "  # Print when a new model is saved or early stopping trigger is reached.\n",
    "  # After the final epoch (or early stopping), load the best model weights and log the test results to wandb\n",
    "\n",
    "  ##### START OF YOUR CODE #####\n",
    "\n",
    "  # Initialize wandb\n",
    "  wandb.login()\n",
    "  wandb.init(config=initial_config, project=\"cmpe49t_project\")\n",
    "\n",
    "\n",
    "\n",
    "  # Create a run directory in your drive (\"/content/drive/MyDrive/CMPE_runs/\" + the current run name that you'll get from wandb)\n",
    "  # run_dir = \"/content/drive/MyDrive/CMPE49t/\" + wandb.run.name\n",
    "\n",
    "\n",
    " # print(\"wandb run name :  \" , wandb.run.name)\n",
    " # run_directory = wandb.run.dir\n",
    " # print(\"run directory is \" ,run_directory)\n",
    "\n",
    "# I have an error here, I could not solve it.. ı could not set the running directory here\n",
    "  #running_directory = os.path.join(\"/content/drive/MyDrive/CMPE49t/\", wandb.run.name)\n",
    "  #wandb.run.dir = running_directory\n",
    "\n",
    "\n",
    "\n",
    "  # Create the model\n",
    "  model = ResNet18(wandb.config.activation, wandb.config.drop_rate, wandb.config.image_size)\n",
    "  model.to(device)\n",
    "\n",
    "\n",
    "  # Create dataloader dictionary with \"train\", \"val\", \"test\" keys\n",
    "  data_dict = {\n",
    "      \"train\": CustomDataset(wandb.config.image_size, wandb.config.data_dir, \"train\"),\n",
    "      \"val\": CustomDataset(wandb.config.image_size, wandb.config.data_dir, \"val\"),\n",
    "      \"test\": CustomDataset(wandb.config.image_size, wandb.config.data_dir, \"test\")\n",
    "  }\n",
    "\n",
    "\n",
    "  dataloader_dict = {x: DataLoader(data_dict[x], batch_size=wandb.config[f\"{x}_batch_size\"], shuffle=True)\n",
    "  for x in [\"train\", \"val\", \"test\"]}\n",
    "\n",
    "  # Define binary cross entropy loss\n",
    "  criterion = nn.BCELoss()\n",
    "\n",
    "  # Define optimizer with weight decay\n",
    "  optimizer = optim.Adam(model.parameters(), lr=wandb.config.learning_rate, weight_decay=wandb.config.l2_reg)\n",
    "\n",
    "\n",
    "  # Set lr scheduler to ReduceLROnPlateau\n",
    "  scheduler = ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.1, min_lr=1e-9)\n",
    "\n",
    "  # Training loop\n",
    "  best_val_acc = 0.0\n",
    "  early_stopping_counter = 0\n",
    "\n",
    "\n",
    "  for epoch in range(wandb.config.nb_epoch):\n",
    "      # Training\n",
    "      model.train()\n",
    "      train_results = training(dataloader_dict[\"train\"], model, criterion, optimizer)\n",
    "\n",
    "    # Check if 'input' and 'target' keys exist in train_results\n",
    "      if 'input' in train_results and 'target' in train_results:\n",
    "    # Convert input and target tensors to float\n",
    "        input_data = train_results[\"input\"].float()\n",
    "        target_data = train_results[\"target\"].float()\n",
    "\n",
    "    # further processing with input_data and target_data\n",
    "      else:\n",
    "        print(\"Missing 'input' or 'target' key in train_results.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "      # Validation\n",
    "      model.eval()\n",
    "      val_results = validation(dataloader_dict[\"val\"], model, criterion)\n",
    "\n",
    "      # Log results to wandb\n",
    "      wandb.log({\"train_loss\": train_results[\"loss\"],\n",
    "                   \"train_acc\": train_results[\"acc\"],\n",
    "                   \"val_loss\": val_results[\"loss\"],\n",
    "                   \"val_acc\": val_results[\"acc\"],\n",
    "                   \"lr\": optimizer.param_groups[0]['lr'],\n",
    "                   \"epoch\": epoch})\n",
    "\n",
    "      # Check for early stopping\n",
    "      if wandb.config.early_stopping > 0 and val_results[\"acc\"] > best_val_acc + 0.01:\n",
    "          best_val_acc = val_results[\"acc\"]\n",
    "          early_stopping_counter = 0\n",
    "          # Save best model weights\n",
    "          torch.save(model.state_dict(), os.path.join(wandb.run.dir, \"best_model.pth\"))\n",
    "          print(f\"New best model saved at epoch {epoch} with val accuracy {best_val_acc:.4f}.\")\n",
    "      else:\n",
    "          early_stopping_counter += 1\n",
    "\n",
    "\n",
    "      if wandb.config.early_stopping > 0 and early_stopping_counter >= wandb.config.early_stopping:\n",
    "          print(f\"Early stopping triggered at epoch {epoch}.\")\n",
    "          break\n",
    "\n",
    "      # Adjust learning rate using scheduler\n",
    "      scheduler.step(val_results[\"loss\"])\n",
    "\n",
    "  # After the final epoch (or early stopping), load the best model weights\n",
    "  model.load_state_dict(torch.load(os.path.join(wandb.run.dir, \"best_model.pth\")))\n",
    "\n",
    "\n",
    "\n",
    "  # Log test results to wandb\n",
    "  model.eval()\n",
    "  test_results = validation(dataloader_dict[\"test\"], model, criterion)\n",
    "  wandb.log({\"test_loss\": test_results[\"loss\"], \"test_acc\": test_results[\"acc\"]})\n",
    "\n",
    "  print(\"Training completed!\")\n",
    "\n",
    "  # [optional] finish the wandb run, necessary in notebooks\n",
    "  wandb.finish()\n",
    "\n",
    "  ##### END OF YOUR CODE #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wwcd18kWfcTT",
    "outputId": "42c688ed-afca-4cc1-d319-29e4d45d8c40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 36lb4mvm\n",
      "Sweep URL: https://wandb.ai/bounteam/cmpe49t_project/sweeps/36lb4mvm\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters that we will fine tune with, which are:\n",
    "  # Activation function\n",
    "  # Optimizer\n",
    "  # Drop rate: should be chosen randomly from a uniform distribution between [0., 0.9]\n",
    "  # Weight decay: should be chosen randomly from a uniform distribution between [0., 0.1]\n",
    "  # Learning rate: should be chosen randomly from a uniform distribution between [0.0001, 0.1]\n",
    "\n",
    "# definition of the parameters\n",
    "\n",
    "\n",
    "# Define the parameters that we will fine-tune\n",
    "parameter_dict = {\n",
    "    \"activation\": {\"values\": [\"relu\", \"leaky_relu\", \"gelu\"]},\n",
    "    \"optimizer\": {\"values\": [\"Adam\", \"SGD\"]},\n",
    "    \"drop_rate\": {\"min\": 0.0, \"max\": 0.9},\n",
    "    \"l2_reg\": {\"min\": 0.0, \"max\": 0.1},\n",
    "    \"learning_rate\": {\"min\": 0.0001, \"max\": 0.1},\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Define the sweep configuration\n",
    "sweep_config = {\n",
    "    \"method\": \"random\",\n",
    "    \"metric\": {\"goal\": \"maximize\", \"name\": \"val_acc\"},\n",
    "    \"parameters\": parameter_dict,\n",
    "    \"name\": \"my_sweep\",  # Customize the sweep name\n",
    "    \"project\": \"cmpe49t_project\",  # Replace with your project name\n",
    "}\n",
    "\n",
    "sweep_config['parameters'] = parameter_dict\n",
    "\n",
    "# Start the sweep\n",
    "sweep_id = wandb.sweep(sweep=sweep_config, project=\"cmpe49t_project\", entity=\"bounteam\") ##### INSERT YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.agent(sweep_id, function=main)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "019d928a40104087a8cb8e78b6ae57d7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1aa8f3f38863426dbcfed87ba2ffdf89": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2ae459a1a1634f8abc0b81e0d86a2475": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b9857bcb86b47679f19d019406ae5ea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3ee7fa02ded348139f4af9b416431555": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ec65596bab9b4311b8b94465c1b11b20",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7d6f6ff9601943958f2ba0a8558eb525",
      "value": 1
     }
    },
    "435ad035502c4010a825cfa4dc140c2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "547de8febeaf403286dd593f738603ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_88f963e4633f41558a8eecea8fbd5988",
       "IPY_MODEL_c21b2a9fe8274554b46eec89e55ec2f4"
      ],
      "layout": "IPY_MODEL_c151efc9f2e94808b4e2430e62286a0c"
     }
    },
    "5ec5a056a6034f9fbc2418f9854be828": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ea54e83f94f34bda9796fe19f545d4d6",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b9c52543baf2420b8be9d2a6f9c598af",
      "value": 1
     }
    },
    "789bf40575a646f3a61b3c8a8d886bf2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d6f6ff9601943958f2ba0a8558eb525": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "828ee842e7514714a2465dc6dbdd91ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cfb976a36be54cc7927441fa202aa5df",
       "IPY_MODEL_3ee7fa02ded348139f4af9b416431555"
      ],
      "layout": "IPY_MODEL_c73e97687e66402ba821789a1bc0bab0"
     }
    },
    "88f963e4633f41558a8eecea8fbd5988": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3b9857bcb86b47679f19d019406ae5ea",
      "placeholder": "​",
      "style": "IPY_MODEL_ed668377c08545028b7d7c6d8856c54b",
      "value": "0.011 MB of 0.011 MB uploaded\r"
     }
    },
    "96ecf33dfd844fe0b7f76043d692835a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_789bf40575a646f3a61b3c8a8d886bf2",
      "placeholder": "​",
      "style": "IPY_MODEL_435ad035502c4010a825cfa4dc140c2d",
      "value": "35.230 MB of 35.230 MB uploaded\r"
     }
    },
    "9ba87571dd024bc396993515644c545b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b9c52543baf2420b8be9d2a6f9c598af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bb74a5127b614513af37b5d9e519db6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_96ecf33dfd844fe0b7f76043d692835a",
       "IPY_MODEL_5ec5a056a6034f9fbc2418f9854be828"
      ],
      "layout": "IPY_MODEL_2ae459a1a1634f8abc0b81e0d86a2475"
     }
    },
    "c151efc9f2e94808b4e2430e62286a0c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c21b2a9fe8274554b46eec89e55ec2f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9ba87571dd024bc396993515644c545b",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1aa8f3f38863426dbcfed87ba2ffdf89",
      "value": 1
     }
    },
    "c73e97687e66402ba821789a1bc0bab0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cfb976a36be54cc7927441fa202aa5df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_019d928a40104087a8cb8e78b6ae57d7",
      "placeholder": "​",
      "style": "IPY_MODEL_e92a80e18c7b4779ae971595e305986b",
      "value": "35.230 MB of 35.230 MB uploaded\r"
     }
    },
    "e92a80e18c7b4779ae971595e305986b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ea54e83f94f34bda9796fe19f545d4d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ec65596bab9b4311b8b94465c1b11b20": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed668377c08545028b7d7c6d8856c54b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
